<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">





















<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.1.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="研究生期间遇到的问题的记录">
<meta property="og:type" content="website">
<meta property="og:title" content="Coding With Yali">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Coding With Yali">
<meta property="og:description" content="研究生期间遇到的问题的记录">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Coding With Yali">
<meta name="twitter:description" content="研究生期间遇到的问题的记录">



  <link rel="alternate" href="/atom.xml" title="Coding With Yali" type="application/atom+xml">



  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Coding With Yali</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
	<a href="https://github.com/jiyali" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Coding With Yali</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Keep Learning</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/04/12/test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JiYali">
      <meta itemprop="description" content="研究生期间遇到的问题的记录">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coding With Yali">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/04/12/test/" class="post-title-link" itemprop="url">test</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-04-12 14:06:57 / 修改时间：15:06:36" itemprop="dateCreated datePublished" datetime="2019-04-12T14:06:57+08:00">2019-04-12</time>
            

            
              

              
            
          </span>

          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/04/12/test/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/04/12/test/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="第一级标题"><a href="#第一级标题" class="headerlink" title="第一级标题"></a>第一级标题</h1><h2 id="第二级标题"><a href="#第二级标题" class="headerlink" title="第二级标题"></a>第二级标题</h2><h3 id="第三级标题"><a href="#第三级标题" class="headerlink" title="第三级标题"></a>第三级标题</h3><blockquote>
<p>~ヾ(◍°∇°◍)ﾉﾞ这是引用<br>多行引用就在连续的每一行之前都加上 &gt;<br>单行引用：<br>悲剧将人生的有价值的东西毁灭给人看，喜剧将那无价值的撕破给人看。——鲁迅</p>
</blockquote>
<p>多行引用方式一（推荐）：</p>
<blockquote>
<p>悲剧将人生的有价值的东西毁灭给人看，喜剧将那无价值的撕破给人看。<br>————鲁迅</p>
</blockquote>
<p>多行引用方式二（不推荐）：</p>
<blockquote>
<p>悲剧将人生的有价值的东西毁灭给人看，<br>喜剧将那无价值的撕破给人看。<br>————鲁迅                            # 这两行由于和上方引用行之间没有空行分隔，也会被当做引用行哦！<br>引用的嵌套结构：<br>马云说：鲁迅先生曾经说过：</p>
<blockquote>
<p>“悲剧将人生的有价值的东西毁灭给人看，喜剧将那无价值的撕破给人看。”</p>
</blockquote>
</blockquote>
<p>往往我们会需要列举一些东西，一二三四五六七什么的，那么我们可以直接使用 [数字].[空格][内容] 的方式来实现：</p>
<ol>
<li>你拍一</li>
<li>我拍二</li>
<li>她拍三</li>
</ol>
<p>如果你不想为他们编号，直接使用 星号 代替[数字].即可：</p>
<ul>
<li>你拍一</li>
<li>我拍二</li>
<li>她拍三</li>
</ul>
<p>链接语法<br>生成链接的 markdown 语法共有两种，一种是内联式，另一种是引用式。<br>内联式的链接由连续的一对中括号和一对小括号组成，中括号里的内容是链接显示出来的文字，小括号里的内容是链接的地址，写法如下：<br>&lt;!–<br><a href="https://11.tt" target="_blank" rel="noopener">这是一个链接</a><br>而引用式的链接则由像这样连续的两对中括号：</p>
<p><a href="https://11.tt" target="_blank" rel="noopener">这是一个链接</a><br>以及像下方这样在文档任意位置的引用标签组成：</p>
<p>综合起来，引用式的写法如下：</p>
<p><a href="https://11.tt" target="_blank" rel="noopener">这是一个链接</a><br><a href="https://11.tt" target="_blank" rel="noopener">1</a>: <a href="https://11.tt" target="_blank" rel="noopener">https://11.tt</a><br>此外，如果想要跳转到同一页面中的某个标题处，只需要将链接位置的内容修改为井号加上标题名称即可，像这样：</p>
<p><a href="#链接语法">链接语法</a><br>但是，同一页面中链接无法使用引用式！</p>
<p>插入图片语法<br>向文中插入图片的方式和链接是十分类似的，只需要在链接语法前加上一个 ! 即可，其中，中括号中的内容是鼠标移到图片上时显示的描述。<br>像这样：</p>
<p><img src="John Gruber.jpg" alt="Markdown 创始人 John Gruber"><br>也可以是这样：</p>
<p><img src="https://11.tt" alt="Markdown 创始人 John Gruber"><br><a href="https://11.tt" target="_blank" rel="noopener">1</a>: John Gruber.jpg  –&gt;</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/06/论文笔记-Show-and-Tell-A-Neural-Image-Caption-Generator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JiYali">
      <meta itemprop="description" content="研究生期间遇到的问题的记录">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coding With Yali">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/03/06/论文笔记-Show-and-Tell-A-Neural-Image-Caption-Generator/" class="post-title-link" itemprop="url">论文笔记-Show and Tell:A Neural Image Caption Generator</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-03-06 19:45:38" itemprop="dateCreated datePublished" datetime="2019-03-06T19:45:38+08:00">2019-03-06</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-09 21:05:54" itemprop="dateModified" datetime="2019-03-09T21:05:54+08:00">2019-03-09</time>
              
            
          </span>

          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/03/06/论文笔记-Show-and-Tell-A-Neural-Image-Caption-Generator/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/03/06/论文笔记-Show-and-Tell-A-Neural-Image-Caption-Generator/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>摘要<br>图像内容的自动描述是连接计算机视觉和自然语言处理的人工智能中的一个基本问题。本文中，我们提出了一种基于深度递归神经网络架构的生成模型，这个模型结合了机器视觉和机器翻译的最新研究进展，这可以用来生成描述图像的自然句子。在给定图片上对模型进行训练，最大化目标描述句子的似然估计。在几个数据集上的实验表明，模型的准确性和它只从图像描述中学习的语言的流畅性。我们通过定量和定性的方式验证了我们的模型在大部分情况下是精确地。例如，当前在Pascal数据集上最先进的BLUE分数（越高越好）为25，我们的方法的到的分数为59，相比之下，人类的表现为69分。我们还展示了在Flickr30k数据集上的BLEU得分的改进，从55到66，在SBU数据集上，从19到27.<br>1.前言<br>能够使用正确的成型的英语句子自动描述一副图片的主要内容是一个非常有挑战性的课题，但是他可以有巨大的影响，比如说帮助视觉受损的人更好的理解网页图像的内容。这个任务要比充分研究的退昂分类或者识别任务困难的多，而这两项任务一直都是计算机视觉领域的主要焦点。事实上，一个描述不仅需要捕获图像中所包含的对象，还需要表达这些对象之间的关系以及他们的属性和他们所涉及的活动。另外，上述语义知识必须用像英语这样的自然语言来表示，这就意味着除了视觉理解，我们还需要语言模型。<br>以前大多数的尝试都是提议将上述子问题的现有方法拼接在一起，来试下图像和它对应描述的转换。我们希望在这一工作中提出一个单一的模型，以图像I作为输入，从一组给定字典中的单词St中，训练产生最大似然概率p(S|I)生成目标序列的单词S={S1,S2,…}，来充分描述图片。<br>我们工作的主要灵感来自最近机器翻译的进步，机器翻译的任务是把用源语言写的句子S通过最大化p(T|S)翻译成目标语言的译文T。多年来，机器翻译也是通过一系列的独立的任务（直接翻译单词，调整单词，重排序等），但是最近的工作表明翻译可以用一个使用RNN的更简单的方式来完成而且达到了最高的性能。一个“encoder”RNN读取原句，并且将它转换成一个丰富的固定长度的向量表示，这个“encoder”反过来可以作为生成目标句子的“decoder”RNN的初始隐藏状态（初始隐藏状态是个啥？）<br>这里，我们建议遵循这个想法，用CNN来替换编码器RNN。在过去几年里，已经有令人信服的证据表明，CNNs可以通过将输入图片嵌入一个固定长度的向量中，生成一个丰富的表现，这个表现可以用于各种视觉任务中。因此，使用CNNs作为图像的“encoder”是自然而然的，首先，对其预训练用来图像分类的任务，并使用最后一层作为生成句子的RNNdecoder的输入。我们称这个模型为“Neural Image Caption”，或者“NIC”。<br>我们的贡献如下。首先，我们为这个问题提供了一个端到端系统。这是一个使用随机梯度下降的完全可训练的神经网络。其次，我们的模型结合了用于视觉和语言的模型的最先进的子网络。这些可以在更大的语料库上进行预训练，从而利用额外的数据。最后，这个系统与最先进的方法相比产生了明显优越的性能；例如，在Pascal数据集上，NIC得到了59分的BLEU分数，目前最先进的方法为25，而人为表现达到了69。在Flickr30k数据集上，我们从55提高到66，在SBU数据集上，我们从19提高到27。<br>2.相关工作<br>从视觉数据生成自然语言描述一直是机器视觉的研究热点，但是主要针对视频。这导致由可视化的原始识别器和结构化的形式语言构成的复杂系统。比如，And-Or Graphs或者logic系统，它们通过通过基于规则的系统进一步转变为自然语言。这些系统都是大量的手工设计的，相对脆弱，而且只在限定额领域进行了演示，比如交通场景或者运动中。<br>自然文本描述静止图像的问题近年来引起了很大的兴趣。借助最近在对象，对象属性和位置的识别方面的研究进展，允许我们驱动自然语言生成系统，尽管这些系统的表达能力有限。Farhadi等人使用detections（信号检测？）来推断使用模板转换为文本的场景元素的三元组。相似的，Li等人以detections开始，使用检测到的对象以及他们之间的关系拼凑出最终的描述。KulKani等人使用了一个比三元组更复杂的graph of detections（探测图），但是使用了基于模板的文本生成。基于语言句法分析的更强大的语言模型也被使用过。以上方法已经能够大致描述图像，但是当生成文本描述时，它们都是手工设计的而且非常严格。<br>大量的研究解决了给定图片描述的排列问题。这些方法基于图像和文本映射到同一向量空间的思想。对于图像查询，检索嵌入空间的与图像相近的描述。最接近的是，神经网络被用于将图像和文字描述嵌入到一起或者(image crops)和句子但是不试图产生新的描述。一般来说，上述方法不能描述以前从未见过的对象组成，即使个别的对象可能出现过在训练数据集中。另外，它们避免解决评估生成的描述有多好的问题。<br>在这项工作中，我们将用于图像分类的深度卷积网络和用于序列建模的循环卷积网络结合在一起，创建了一个生成图像描述的单一网络。RNN是在这种简单的“端到端”网络中上下文中训练的。这个模型受最近机器翻译中序列生成的成功的启发，不同的是我们提供了一个卷积网络处理的图像而不是以一个句子开始。最近的研究是Kiros等人，他们用了一个神经网络，但是是一个前馈的神经网络，给定一幅图片和之前的单词来预测下一个单词。Mao等人最近的研究中使用了递归神经网络来做相同的预测任务。这与最近的提议非常相似，但是有一些重要的区别：我们使用了一个更有力的RNN模型，并直接向RNN模型提供可视化输入，这使得为RNN记录文本解释过的对象成为可能。由于这些看起来似乎无关紧要的差距，我们的系统在已建立的基准上取得了更好的结果。最后，Kiros等人提出使用一个强大的计算机视觉模型和一个编码文本的LSTM建立一个结合多模态嵌入空间。和我们的方法相反，他们使用的是两个独立路径（一个用于图像，一个用于文字）来定义联合嵌入，并且，即使他们可以生成文本，他们的方法在排名上是(highly tuned)(高度调整？？)<br>3.模型<br>本文中，我们提出一个神经和概率框架来生成图像的描述。最近机器翻译的最新进展表明，给定一个强大的句子模型，就有可能通过直接最大化使用“端到端”方式让给定句子的正确翻译的概率实现先进的结果——同时用于训练和推理。<br>这些模型使用现有的递归神经网络，它将变长的输入编码到一个固定维数的向量中，然后利用这些表示形式解码到期望的输出语句。因此，使用相同的方法是很自然的，给定一张图片（而不是源语言的输入语句），一个相同的原理“翻译”成它的描述语句。<br>因此，我们提出使用如下的公式直接最大化给定图像的正确描述的概率：<br>（公式）<br>这里的θ是我们模型的参数，I是图像，S是正确的描述。由于S代表任何句子，它的长度是无限的。因此，利用链式法则对S0,…,SN的联合概率建模，这里的N是这个特殊例子的长度<br>（公式）<br>为了方便起见，我们放弃了对θ的依赖。在训练时，(S,I)是训练样本对，我们使用随机梯度下降法对整个训练集使用如公式(2)所描述的方法进行优化log概率和(进一步的训练详情将在第4节给出)。<br>p(St|I,S0,…,St-1)与循环神经网络建模，可变数量的单词我们假定为t-1(没看懂这句话的原文hhh…),由定长的隐藏状态或内存Ht表示。在看到一个新的输入xt后，使用非线性函数f来更新这个内存：<br>（公式）<br>为了使上述的RNN更加具体，需要作出两个关键的设计选择：f的确切形式是什么，图像和单词怎么才能作为xt的输入。对于f我们使用上短期记忆网络，他在翻译等顺序任务上显示了先进的性能。这个模型将在下一节进行概述。<br>对于图像的图像的表征，我们使用CNN。它们在图像任务中得到了广泛的应用，目前是用于目标识别和检测的最新技术。我们选择CNN是根据它是ILSVRC2014年分类竞赛的获奖作品。此外，它们还被证明可以通过迁移学习推广到其他的任务上去，比如说场景分类。单词用嵌入模型表示。<br>3.1基于LSTM的句子生成器<br>(3)中f的选择取决于它处理消失和爆炸梯度的能力，这是设计和训练RNNs中最常见的挑战。为了处理这种挑战，引入一种特殊的形式的循环网络LSTM，并成功应用于翻译和序列生成。<br>LSTM模型的核心是一个内存单元c编码，它对每一时间步所观察到的内容编码(见图2)。记忆单元的行为是由“门”控制的，门层被多次应用，因此，如果门是1，则可以从门层中保留一个值，如果门值为0，则删掉这个值。特别的是，使用了三个门来控制是否忘记当前的记忆单元的值（遗忘门f）。如果应该读取输入(输入门i），以及是否输出新的单元值（输出门o）。门和单元更新的输出的定义如下：<br>这里的(符号)表示门值的积，各W矩阵为训练后的参数。这样的乘法门使得训练LSTM成为可能，因为这些门可以有效地解决爆炸和消失梯度的问题。非线性函数分别是sigmod σ 和双曲线h。最后一个方程mt是用来输入softmax的，他将生成所有单词的概率分布pt。<br>训练：训练LSTM模型，当它看到图像和之前由p(St|I,S0,…,St-1)定义的单词,去预测使句子中的每个单词。为此，以展开的形式思考LSTM是有指导意义的——为图像和每个句子单词创建LSTM记忆副本，以便所有LSTMs共享相同的参数和LSTM在t-1时刻的输出m-1输入到t时间的LSTM中去(见图3)。在展开版本中，所有的重复连接都被转换为前馈连接。更详细的说，如果我们用I来表示输入图像，S={S0,…,SN}来表示描述这幅图像的正确的句子，展开过程如下：<br>（公式）<br>其中，我们将每个单词表示为一个one-hot向量St，其维数等于字典的大小。注意，我们用S0表示一个特殊的起始值，用SN表示一个特殊的终止单词，他们表示句子的开始和结束。特别是当LSTM信号输出终止单词时，表示生成了一个完整的句子。图像使用视觉CNN和文字使用文字嵌入We同时被映射到同一空间。图片I只在t=-1时被输入一次，告诉LSTM图片的内容。我们通过实验验证，在每个时间步长的输入图像作为额外的输入时，网络可以明确的利用图像中的噪声更容易过拟合，所以结果很差。<br>我们的损失是每一步正确单词的负对数可能性的总和如下：<br>（公式）<br>将上述损失最小化图像嵌入器的顶层和字嵌入We的LSTM所有的参数。<br>推论：有很多方法可以使用NIC为给定图片生成句子。首先是抽样，我们根据根据p1对第一个单词抽样，然后提供相应的嵌入作为输入，并且对p2抽样，一直这样一直到我们对特殊的句末标记或某个最大长度进行抽样。第二种方法是BeamSearch：迭代考虑时间t的k个最佳句子作为候选句，生成大小为t+1的语句，并且只保留最佳结果中的k个。这个更接近S=argmaxs’p(S’|I)。在接下来的实验中，我们使用BeamSearch方法，一束大小为20。使用大小为1的（即贪婪算法）平均降低了我们的结果2个BLEU点。<br>4.实验<br>为了与现有的技术相比较，我们使用了几个度量标准、数据源和模型架构做了大量的实验来验证我们模型的有效性。<br>4.1评价标准<br>尽管有时并不清楚一个描述是否应该被认为是成功的，或是不是给定图像的描述，现有技术提出了几个评估指标。最可靠的（但耗时）是要求评分者对给定图像的每个描述的有效性进行主观评分。在本文中，我们使用这个来加强一些确实与自动度量相关的主观评分，遵循[11]提出的指导原则，这个指导原则要求评分者用1-4的分值来评估每个生成的句子。<br>对于这个度量，我们设定了一个Amazon Mechanical Turk实验。每张图片由两个工作人员来评分。工作人员之间的一致性大概在65%的水平上。在出现分歧的情况下，我们简单的对分数进行平均计算，并将平均分记录为最终得分。对于方差分析，我们使用booststrapping(对结果进行重新采样作为新的样本，并对新样本进行平均值、标准差的计算)。像[11]中一样，我们报告了大于或者等于一组预定义阙值的分数的百分比。<br>假设可以接近基本事实，即人类生成的描述，剩下的度量标准可以自动计算。到目前为止，图像标注文献中最常用的度量标准是BLEU分数，它是生成句子和参考句子之间单词n-gram的精度的一种形式。即使这个度量有着明显的缺点，他仍然被认为与人类评估有着良好的相关性。在我们的工作中，我们也证实了这一点，正如我们在4.3节中所介绍的。在补充材料中可以看到我们的系统的输出结果还有广泛的评价方案。<br>除了BLEU，给定一个翻译可以用模型的复杂度评估（这与(1)中的目标函数密切相关）。复杂度是每个预测单词的逆概率的平均值。我们使用这个指标来执行关于模型和超参数调优的选择，但是我们没有报告因为BLEU总是首选的指标。<br>最后，当前关于图像描述的文献也一直在使用代理任务，即给定图片对一组可用的描述进行排序(参见[13])。这样做的好处是可以使用一直排名的指标，比如recall@k。另一方面，将生成描述的任务转换成重排序的任务不是那么让人满意：随着图像描述的复杂度的增加，连同他的字典，可能的句子的数量随着字典的大小呈指数型增长，并且一个预先定义的句子与新图像匹配的可能性也会下降，除非此类句子的数量也呈指数型增长，但这是不现实的。更不用说为每个图像都高效的评估这么大的语料库的潜在复杂性了。同理也被应用到语音识别中，在语音识别汇中，必须生成与给定给定声音序列相对应的句子，虽然早期的尝试集中于音素或者单词的分类，但是这项任务的最先进的方法现在是可以生成的，可以从大型的字典中生成句子。<br>我们的模型可以生成合理质量的描述，而且尽管评估图像描述的模糊性（可能有很多有效的描述并不在groundtruth（标定数据？？）中），我们认为我们的应该专注于生成任务而不是重排序的评价指标。<br>4.2数据集<br>为了评估我们使用了大量的数据集，这些数据集由图像和描述这些图像的英文句子构成。数据集的统计数据如下：<br>（表格）<br>除了SBU，每张图片都有5个相对直观和公正的句子标签进行了标注。SBU由图片所有者在上传到Flickr时给出的描述组成。因此他们不能保证是直观的或无偏差的，也因此这个数据集有更多的噪声。<br>Pascal数据集通常只在系统在其他四个数据集中的任意一个数据进行了培训之后才用于测试。在SBU的例子中，我们拿出1000张图片用作测试，剩下的按照[17]中使用的方式进行训练。类似的，我们将MSCOCO验证集中的4k图片作为测试集，称为COCO-4k,并在下一节中给出它的使用报告。<br>4.3结果<br>由于我们的模型是数据驱动，端到端训练的，并且给定了大量的数据集，我们想要回答诸如：“数据集大小如何影响泛化”，“它能够实现什么样的迁移学习”，和“它怎么处理弱标记的例子”。因此，我们对五个不同的数据集进行了实验，如4.2节所述，这使我们能够深入理解我们的模型。<br>4.3.1训练细节<br>我们在训练汇总面临的很多挑战都与过拟合相关。的确，纯粹的监督学习方法需要大量的数据，但是高质量的数据集只有不到10万张图片。分配描述的任务比对象分类的任务更困难，数据驱动的方法直到最近才成为主流，这要归功于ImageNet这样大的数据集（除了SBU之外，ImageNet的数据集是我们文章中描述的数据集的十倍）。因此，我们相信，即使我们获得了相对好的结果，我们的方法的优势在于相对于现在人工设计的方法在未来的几年随着训练集的增加而更加明显。<br>尽管如此，我们探索了几种处理过拟合的技术。一个最明显的方式是将我们的的系统中的CNN组件的权重初始化为一个预训练模型上的权重（比如说ImageNet）。我们在所有的实验中都做了这个处理（类似于[8]），他确实在泛化方面有很大的帮助。另一组可以被合理初始化的权重是We，单词嵌入。我们尝试从一个大型的新闻语料库[21]初始化它们，但是没有明显的效果，为了简单起见，我们决定不初始化它们。最后我们做了一些模型级的避免过拟合的技术。我们尝试dropout and ensembling[33]模型，以及通过权衡隐藏单元的数量和深度来检测模型的大小（比如容量）。dropout and ensembling给出了关于BLEU的改进，这就是我们在本文中报告的。<br>我们用随机梯度下降法固定学习率和消除动量来训练所有的权重。所有的权重除了CNN权重都是随机初始化的，我们没有改变CNN的权值，因为会产生负面影响。我们使用了512的嵌入维度和LSTM记忆的大小。进一步的实施细节将作为补充材料的一部分公布。<br>描述用基本的标记化来进行预处理，保持训练集中出现至少5次的所有单词。<br>我们使用复杂度进行早期的干预和模型的选择，但是我们和以往的研究一样报告了BLEU-1的得分（即，unigram精确度），BLEU-1与人类评估很好的相关。<br>4.3.2生成结果<br>我们将所有数据集的主要结果放在了表格1中。由于PASCAL没有训练集，我们使用了MSCOCO训练的系统（MSCOCO可以说是这一任务的最大最高质量的数据集）。PASCAL和SBU最先进的研究成果并没有使用基于深度学习的图像特征，因此可以说，对这些分数的巨大改变仅仅来自这一变化。Flickr数据集最近才被使用，但是大部分情况下是在检索框架中评估的。一个值得注意的例子是[20]，它们同时进行检索和生成，并且在Flickr数据集上产生了迄今为止效果最好的性能。<br>表1中的人类评分是通过比较其中一个人类标题和另外四个标题计算出来的。我们为这五个评分者中的每个都评分，并且对它们的BLEU得分进行平均。因为这给我们的系统带来了一点优势，BLEU得分是根据5个参考句子而不是4个计算出来的，我们把5个参考句子的平均差加到人类得分上。<br>鉴于该领域在过去几年中取得了一些令人印象深刻的进展，我们确实认为报告在bigram或者trigram级别上的BLEU得分很有意义。我们在Flickr8k上的结果见表2，与[20]相比有显著的改善（在Flickr30k上更高水平的BLEU也有类似的趋势）。<br>4.3.3迁移学习，数据大小和标签质量<br>因为我们已经训练了很多模型，并且我们有几个测试集，所以我们想要知道是否可以将一个模型迁移到另一个数据集上，并且域上不匹配能得到像更高质量的标签或者更多的训练数据多少补偿。<br>迁移学习最明显的例子是在Flickr30k和Flickr80k之间。这两个数据集的标签类似，因为他们是相同的组创建的。的确，在Flickr30k上训练（训练数据多4倍），得到的结果明显更好，如图2所示。很明显的是，在这种情况下，我们发现可以通过添加更多的训练数据来提高准确率，因为整个过程都是数据驱动的，而且容易发生过拟合。MSCOCO甚至更大（比Flickr30k要多5倍的训练数据），但是由于收集过程不同，所以很有可能有更多的词汇差异和更明显的不匹配。事实上，所有的BLEU得分都会下降10点（例如BLEU-1只有54）。尽管如此，这些描述仍然是合理的。<br>由于PASCAL没有正式的训练集并且独立于Flickr和MSCOCO收集的，所以我们报告了从MSCOCO学习的迁移（见表1）。从Flickr30k上的迁移学习产生的效果更差，BLEU-1只有53。<br>最后，即使SBU有弱标签（即，标签是标题，而不是人工生成的描述），使用更大、更嘈杂的词汇表，任务要困难的多。然而，更多的数据可供训练使用。当在SBU上运行MSCOCO模型时，我们的性能从28降到了16。<br>4.3.4生成多样性的讨论<br>在训练一个给定p(S|I)的生成模型之后，一个明显的问题是这个模型是否生成了新的标题，以及生成的标题是否既多样又质量很高。<br>表格3显示了从我们的beam search decoder返回N-best列表而不是最佳假设时的一些示例。注意，这些示例哪里不同，并且可能显示来自同一图像的不同方面。该协议的前十五个生成句子的BLEU得分为58，与人类的得分很相近。这表明模型生成的多样性的数量。粗体表示训练集中没有出现的句子。如果我们选择最好的候选者，80%的情况下这个句子出现在训练集中。这并不奇怪，因为训练数据的数量很小，所以模型选择“范例”句并使用他们生成描述相对容易。相反，如果我们分析前15个生成的句子，一般情况下我们看到的是新的句子，但仍有相似的BLEU分数，表明他们有足够的质量，但是他们提供了一个有效的多样性。<br>4.3.5排序结果<br>虽然我们认为重排序作为评估从图片生成的描述是一种差强人意的做法。但是很多论文都报告了排名的得分，给指定的测试图片使用一组测试标题作为候选者排名。这种方法对这些度量指标(MNLM)是最有效的，特别是应用ranking-aware损失。然而，NIC是在两个排序任务(排序给定图像的描述。排序给定描述的图像)上都做的非常好，如表4和表5所示。注意，对于图像标注任务，我们将分数标准化，与[20]使用的分数类似。<br>4.3.6<br>图4显示了NIC提供的描述的人工评估结果以及各种数据集上的参考系统和groundtruth。我们可以看到NIC比参考系统要好，但是明显不如groundtruth，这是意料之中的。这表明BLEU并不是一个完美的度量标准，因为它不能很好的捕捉到NIC和评分者评估的人类描述之间的差异。评估的图像如图5所示。有趣的是，例如在第一列的第二幅图片中，模型时如何能够注意到飞盘的大小的。<br>4.3.7分析嵌入(Embedding)<br>为了表示前面的单词St-1作为解码LSTM的输入输出St，我们使用字嵌入向量[21]，它的优点是独立于字典的大小（与简单的one-hot-encoding方法相反）。此外，这些词嵌入可以与模型的其他部分联合训练。值得注意的是，怎样学习表示从语言的统计数据中捕获一些语义。表4.3.7显示了一些示例单词在学习嵌入空间中找到的最近的其他的单词。<br>注意模型学习的一些关系将如何帮助视觉组件。事实上，“马”“小马”和“驴”相互靠近会鼓励CNN提取与马类动物相关的特征。我们假设，在我们很少看到的类的这种极端的情况下（例如，“unicorn”),它与其他的词嵌入（例如，“horse”接近可以提供更多的信息，这些信息可以完全被基于单词的传统的方法所忽略掉。<br>5.结论<br>我们提出了一种端到端的神经网络系统NIC，他可以自动的查看图像并且生成可以用浅显的英语描述的合理的标注。NIC基于卷积神经网络，它将图像编码成紧凑的表示形式，然后递归神经网络生成相应的句子。这个模型经过训练，使给定的图像的句子的可能性最大化。在几个数据集上的实现，包括Pascal,Flickr8k,Flickr30k和SBU上分别从定性的（生成句子非常合理）和定量评价两方面展示了NIC的鲁棒性。从这些实验中可以明显的看出，随着用于图像描述的可用数据集的大小的增加，NIC等方法的性能也会提高。此外，观察如何使用非监督数据（单独来自图像或者单独来自文本）来改进图像描述方法将非常有趣。</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/25/论文笔记-From-Captions-to-Visual-Concepts-and-Back/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JiYali">
      <meta itemprop="description" content="研究生期间遇到的问题的记录">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coding With Yali">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/25/论文笔记-From-Captions-to-Visual-Concepts-and-Back/" class="post-title-link" itemprop="url">论文笔记-From Captions to Visual Concepts and Back</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-25 14:24:12" itemprop="dateCreated datePublished" datetime="2019-02-25T14:24:12+08:00">2019-02-25</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-05 19:30:59" itemprop="dateModified" datetime="2019-03-05T19:30:59+08:00">2019-03-05</time>
              
            
          </span>

          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/02/25/论文笔记-From-Captions-to-Visual-Concepts-and-Back/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/02/25/论文笔记-From-Captions-to-Visual-Concepts-and-Back/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>摘要<br>本文展示了一种自动生成图像标注的新方法：直接地从图像标注数据集中学习的视觉检测器和语言模型。我们使用的是多示例学习去训练在标题中常见词的视觉检测器，这些常见词包括很多不同的词性包括名词、动词和形容词。单词检测器的输出用作最大熵语言模型的条件输入。这个语言模型从一组超过400,000图像标注中学习，来捕捉单词用法的统计量。我们通过使用句子级的特征和多模态相似性模型来对标题候选者的重新排序，从而获得全局语义。<br>1.前言<br>什么时候说明机器理解了图片呢？一个定义是：当它可以生成一个新的标题来概述图片中突出的内容比如图片中出现了什么目标、他们的特征、或者目标之间的关系时，就说机器理解了图片。决定主要内容的不仅需要知道图片内容，而且还需要通过常识推断出场景的哪个方面可能有意思或者很新颖。<br>本文描述了一个从样本中生成图像标注的新方法。我们从图片以及相应的图像标注数据集中训练我们的标题生成器。以前生成图像标题的方法依赖于目标、特征和从单独的手动标注的训练集中学习到的关系探测器。<br>在训练中直接使用标注有两个明显的优势。首先，标题只是包含内在的显著的信息。比如说一个从包含“小狗”这个单词的很多有标题的图片中训练出来的小狗探测器可能偏向于探测突出的小狗，而不是背景中的小狗。图像标注也包括各种各样的单词，包括名词、动词还有形容词。因此，我们需要学习与各种概念相关的探测器。当有些概念，比如说“骑”或者“漂亮”，在理论上可能非常难学习。这些术语可能与特定的视觉形态高度相关（如一个人骑在马上或者日落时在山上。<br>其次，在图像标题上训练语言模型可以获取关于场景中的常识性知识。一个语言模型可以学习到一个人更可能坐在椅子上而不是站在椅子上。这个信息消除了噪声视觉检测的歧义。<br>我们的方法流程如图一所示。首先我们用弱监督学习为一组图像标注中的常用单词构造一个检测器。直接从图像标注中学习是很难的，因为系统并不能利用像对象候选边界框这种在别的数据集中找到的监督信号。很多单词，比如说“拥挤”或者“内部”，甚至没有定义良好的候选边界框。为了克服这个难点，我们使用三个想法。系统使用对象建议生成器查找图像区域。下一步，我们使用预处理的ImageNet卷积神经网络特征对每个区域进行特征化。最后，我们把每个区域的特征映射到可能包含在标注中的一组词汇中去。我们用多示例学习来训练这个映射去确定每个单词信息量最大的图像区域。<br>从可能的词袋产生新的图像标注需要有效的语言模型。在本文中，我们把标注生成看做一个优化问题。这样看来，核心任务就是拿到一套单词检测的分数集，然后找出每个单词都恰好包含一次的最大可能性的句子。我们从一组训练图像标注中训练出一个最大熵语言模型。这种训练通过语言统计学获得关于这个场景的常识性知识。对单词序列进行显示搜索可以有效找出一组可能性高的句子。<br>系统的最后一阶段通过对句子特征进行加权处理重排了这组高似然句子。这些权重通过最小错误率训练学习得到。除了几个普通的句子特征，我们还介绍了一个基于深度多模态相似性模型的新的特征。深度多模态相似性模型学习两个神经网络将图像和文字片段映射到一个公共向量上，这样就能很容易的测量句子和图片之间的相似性。我们论证了，深度多模态相似性模型显著提高了选择句子的质量。<br>为了鉴定我们自动标注的质量，我们用了三个易于计算的指标，以及在“Amazon’s Mechanical Turk”上与人类受试者做了更好/更差/相等的比较。测试是在具有挑战性的”Microsoft COCO“数据集上进行的，这个数据集包含复杂的多个目标的照片。82,783训练图片每一个都有人工注释的标题。为了测定我们句子的质量，我们使用了流行的”BLEU,METEOR还有perplexity (PPLX)”指标。我们惊喜的发现，我们生成的标注在“BLEU”指标上尽然胜过了人类。当人类受试者评估时，受试者发现我们的标注在23%的情况下有着与人类同等质量甚至超过人类。我们也比较了以前在“PLSCAL”语句数据集上的准确性。我们的结果表明，直接在图像标注上同时训练视觉探测器和语言模型和使用全局语义模型来重排标题候选者都是非常有效的。<br>2.相关工作<br>有两个训练良好的自动生成图像标题的方法：检索现有的人工标注的图像标题，生成新的标题。最近基于检索的方法已经使用神经网络将文本和图像映射到一个公共向量中。其他基于检索的方法使用的是预定义的图像特征的相似性指标。Farhadi等人提出将图像和文字作为一个linguistically-motivated（暂时不懂怎么翻译）语义三元组，然后在这个语义三元组中计算相似性。在神经网络的环境下对句子和图像进行了相似的细粒度分析发现对检索的用处不大。<br>基于检索的方法经常返回一个结构良好的人工标注的标题，但是这些标题可能不能很好的描述新目标的组合或者一个新的句子。这种限制导致了大量的工作，首先需要分析图像和图像中检测到的对象，然后生成新的标题。我们把之前在生成过程中使用的语法和语义的限制的研究和当前最先进的技术进行了比较。我们研究了利用最大似然估计结合句法结构生成新句子的”Midge“系统，并将它与选择通过条件随机场预测的最可能的图像标签来填充句子模板的”Baby Talk“系统进行了定性比较。这两个先前的系统使用了相同的测试句子集，使得直接对比两个系统成为了可能。<br>最近，研究人员探索了从图像中引导语言模型的纯粹的统计方法。Kiros等人从图像派生出的文本模型中提取出图像中的偏置特征使用“log-bilinear”模型，Kiros的模型通过采样对标题进行排序和生成。Mao等人探索了图像条件递归神经网络的使用。这两种方法都没有使用明确的出事对象检测步骤。<br>类似于最后两种方法，我们的研究重点为以图像内容为引导的语言生成。不同于这些方法的是，我们通过将CNN应用到图像区域中检测图像中的单词，并将这些单词用MIL进行信息整合。我们还通过直接从标题训练来最小化句子结构的先验假设。最后，与Kiris,Mao相比，我们将生成问题当做一个最优化问题，并寻找最可能的句子。<br>3.字检测<br>我们生成标题流程的第一步是检测出一组最可能是图像标注的一部分的单词。这些单词可能属于任意一种词性，包括动词，名词和形容词。我们规定我们的词汇表V使用1000个训练标题中的常用词汇。这个词汇表包含了训练标题中出现的92%的单词。整个词汇表会在附录中展示出来。<br>3.1训练单词检测器<br>给出了词汇表，我们下一步的目标是从图像中检测单词。当我们不知道与单词对应的图像候选边界时我们不能使用标准监督学习技术。事实上，很多单词比如像“打开”或者“漂亮”的含义并不能很容易的定义它的候选边界框。一个可能的方式是使用图像分类器作为整个图像的输入。在我们展示的第6节里，这将导致性能下降因为很多单词或概念只适用于图像的子区域。相反的，我们用多实例学习的弱监督方法来训练我们的探测器。<br>属于词汇表V的每个单词ω，MIL将候选边界框的“正”“负”袋作为输入集。每个袋相当于一张图像。对于单词ω和图像i，如果单词ω在图像i的描述中时，一个包bi就会将其描述为“正”,反之为负。直观地来说，MIL通过迭代的在“正”包中寻找“正”实例来进行训练，接着用更新“正”标签的方法反复训练探测器。使用Zitnick and Doll´ar的对象建议生成器Edge Boxes 70可以生成每张照片64组候选边界框的计算效率。<br>我们使用noisy-OR版本的MIL，这个版本中包含单词ω的包bi的概率是由词袋中单个实例的概率计算的：<br>这里的（公式）包含单词ω包bi的概率取决于包中每个实例的概率：<br>这里的（公式）是图像i中的候选边界框j对应单词ω的概率。对于每个候选边界框，我们将ImageNet数据放到卷积神经网络的fc6层去训练来计算特征，这些特征已经被证明不仅仅适用于ImageNet的分类任务，而且还适用于各种视觉任务。我们对图像i中的选择框j的fc6的特征Φ(bij)使用了逻辑函数（公式）来计算p(公式）。这里的vω与单词有关系的权重，uω是偏差<br>3.2对测试图片生成单词<br>给定一个新的测试图片i，我们得出n个对象的候选编辑框bij,j∈n。我们对每个候选编辑框使用公式2来计算得分p(公式）。图像标注中出现的单词ω对应的得分p（公式）对应于所有从noist-OR函数计算得到的j的p（公式）的聚合。我们对所有词汇表V中的单词都这么做。请注意所有的词汇探测器早就独立的训练过，因此他们的输出需要校正。为了校正从不同探测器的输出，我们使用图像级可能性p(公式）来计算训练数据的一个扩展子集的精度。我们以全局阙值来评估这个阙值精度。然后输出所有单词V的精度或者和图像级可能性p（公式）结合的更高的精度。<br>公式2向我们展示了一些简单的MIL检测。对于每张图片，我们画出候选边界框。注意，这个方法没有使用任何的边框注释进行训练，但是仍然可以有效的将对象区域化，也可以有效将图像区域和更抽象的概念结合起来。<br>4.产生语言<br>我们将生成过程转换成搜索基于视觉检测到的单词集所能组成的最可能的句子。这个语言模型是整个过程的核心，因为它定义了单词序列的概率分布。注意虽然LM是个概率模型，但是他可以将有意义的信息进行编码，例如“跑步”更可能跟在“马”后面而不是跟在“说话”后面。这些信息可以帮助识别错误的单词检测，并将世界上的常识性知识进行编码。<br>4.1统计模型<br>为了生成图像的候选标题，我们使用基于视觉检测到的单词集的最大熵LM。最大熵LM以前面ω1，ω2……，ωl-1以及前面句子中还没提到的存在于可能性最大的检测单词表Vl中的单词,来估算ωl的概率。以没有使用的单词为条件的动机是鼓励使用所有的单词来避免重复。前十五个最频繁的封闭性词类从集合V中剔除，因为他们几乎在每幅图片中都会被检测到（而且由LM可以任意生成）。注意检测到的单词通常比较嘈杂。因此，当预测句子结束标记时，剩下的单词集可能仍然包含一些检测置信度较高的单词。<br>根据最大熵LM的定义，基于在前面出现过的单词以及后面出现的对象所推测出来的最可能的词可以写作：（公式）<br>这里的“&lt;s（开始标记符）&gt;”表示句子的开始标记，fk和λk分别表示第k个最大熵及这个最大熵的权重。表1总结了我们使用的基本的离散最大熵特征。这些特征来源于我们“baseline”系统。事实证明，使用“得分”特征根据相应的视觉探测器来计算单词的对数似然是有效的。我们也用distant bigram特征和连续空间对数双线性特征做了实验，尽管这些明显改进PPLX，但是他们并没有改善BLEU,METEOR或者human preference，而且空间限制也妨碍了进一步的讨论。<br>为了训练最大熵LM，目标函数基于以相应的的检测对象集中为条件的标题的对数似然（公式）这里的上标(s)表示训练数据集中的句子索引，#(s)表示句子的长度。噪声对比评估(NCE)的技术被用于避免计算式子（3）的分母来加速训练。在生成过程中，我们使用非标准化的NCE似然估计，它比标准的NCE似然估计要有效得多，并且能产生非常相似的输出。然而，我们报告中的所有PPLX数据都是经过彻底的标准化计算的。最大熵特征应用在散列表中就像文献[29]中一样。在我们的实验中，我们使用N-gram从1个单词到4个单词的情况，以及使用了15个对比样本进行了NCE训练。<br>4.2产生过程<br>在产生阶段，我们演示了一个类似于文献[38]中使用的一种从左到右的定向搜索方法。这保持了一堆长度为l的部分假设。在研究的每一步中，每一段在堆栈上长度为l的路径都被加上一段可能的单词，得到的结果为长度l+1的路径被存储起来。前k个长度为l+1的路径被保留下来，剩下的被丢掉。<br>我们定义可能作为延长部分的是“句子结束部分”记作“&lt;/s（结束标记符）&gt;”，100个最频繁的单词被归类到可能被提及到的单词，所有在训练集中出现的单词都被发现跟在假设中的最后一个单词后面。剪枝基于部分路径的可能性。当“&lt;/s结束符号&gt;”产生时，“&lt;/s结束符号&gt;”的完整路径将从堆栈中删除，并将保留为一个完整的句子。这个过程将一直持续到句子长度达到最大长度L。<br>在得到一组完整的句子C后，我们得到了一个如下的M-best列表。给定目标数量为T的被提及的图像属性，C中的序列包含至少T个对象被加到M-best列表中，按对数似然降序排序。如果发现C中有少于M个序列包含至少T个对象，我们将T依次减1直到M个序列被找到。<br>5.句子重排序<br>我们的语言模型生成一套M-best语句。我们最后的一个阶段使用MERT来对句子重新排序。MERT使用在整套句子的基础上计算一个线性组合特征，这些特征比如像句子长度，不能在原始的生成过程中使用。MART模型使用BLEU度量在M-best列表上训练验证集，并且应用测试集的M-best列表。最后，经过重排序的最优的序列被选中作为图片的标注。<br>随着几个标准的特征的使用，我们介绍了一个新的多模态相似模型，将在下面进行讨论。MERT所使用的特征的完整清单见表2.<br>5.1深度多模态相似性模型<br>为了表示图片和文本的全局相似性，我们提出了一个深度多模态相似性模型（DMSM）。DMSM学习到将图像和文本片段映射到公共向量中去的两个神经网络。我们用测量图像和文本相对应的向量的数量积相似性来度量图像和文本的相似性。这个数量积被MERT用来重排序句子。DMSM与基于深度网络的语义模型（DSSM）密切相关，只是将其扩展到多模态设置。DSSM最初被提出是为了对文本搜索查询和文档的语义关联性进行建模，在本工作中进行了扩展，将原始的DSSM查询向量替换为深度卷积神经网络计算的图像向量。<br>DMSM由一对神经网络组成，一个神经网络用于将每个输入进行联合训练后映射到一个共同的语义空间。在训练中，数据由一组图像、标题对组成。训练过程中的最小化的损失函数表示给定相应图像的标题的负对数后验概率。<br>图像模型：我们通过由多个卷积层、最大池化层、相应归一化和全连通层组成的深度卷积神经网络将图像映射到语义向量。这个架构在大规模的图像分类中取得了非常成功的效果，并且学习到的特征被证明可以应用在各种各样的视觉任务中。收到这些成果的激励，为了简化训练，我们没有重新学习我们模型中全部的权重。相反的，我们使用在ILSVRC2012图像分类数据集上训练好的网络初始化了一些图层，并且只在上面训练了前几个全连接层的权重。因此，虽然这个模型非常深（有12层），我们没有在前七层中训练权重值。我们根据验证集的性能交叉验证了其它层的数量。模型的全连接层最后一层的表征是给定图片的语义向量，必须与文本模型的最后一层有相同的大小，才能计算出他们之间的余弦相似度。<br>文本模型：DMSM的文本部分以与原始的DSSM相同的方式将文本段映射到语义向量上。一般来说，当文本段被视为一个可以被表示为使用固定大小的单词计数向量的词袋时，可以是一个完整的标题。根据文献[16]我们将词汇计数向量转变为letter-trigram count vector，使用将上下文相关的字母计数分布来表示一个单词。这种表示的优点是减少了输入层的大小，同时很好的归纳了不常见、没见过的以及拼写错误的单词。这种表示前向传播到一个深度全连接网络，在最后一层生成一个语义向量。<br>对象和训练：我们定义相关性R为图片或者查询和基于他们的表示形式yQ和yD的文字段或者文档Q的余弦相似性得到图像和文本模型：<br>对于给定的文本图像对，我们可以通过公式(6)来计算文本和图像相关的后验概率，这里的γ是使用验证集确定的平滑因子。D表示应该与查询（图像）相比较的一组候选文档（标题）的集合。我们发现将D限制为一个匹配的文件D+并随机的选择固定数字N的不匹配文件D-工作良好，虽然使用噪声控制估计可以进一步的改善结果。因此，对于每一张图像，我们选择一个相关的文字段和N个不相关文字段来计算后验概率。在训练过程中，我们调整模型的参数Λ，使相关字标注和匹配的图像之间的负对数后验概率最小化。（公式7）附加的细节在附录中给出。<br>6.实验结果<br>接下来我们将描述用于测试的数据集，然后评价我们的单次检测的方法和句子生成的实验结果。<br>6.1数据集<br>我们大部分的实验结果就是在MicrosoftCOCO数据集上面的汇报的。这个数据集包含82,783训练图片和40,504张校验图片。由于大部分的照片包含多个对象和中腰的上下文信息，因此这些图片为图像标注创建了一个具有挑战性的测试平台。COCO数据集为每张图片提供了五组人工注释的标题，总共有超过400k的标题。测试的注释是很难得到的，所以我们将验证集分为验证集和测试集。<br>为了与之前的论文进行试验对比，我们还报告了PASCAL语句数据及的实验结果，该数据集包含了来自2008年VOC Challenge的1000张图片，每张图片有6个人工标注的标题。<br>6.2单词检测<br>为了深入理解我们使用MIL进行单次检测的弱监督的方法，我们度量了他=这种方法在单词分类任务上的精确度。注意这是一项极具挑战性的任务，因为概念上相似的单词是单独分类的，比如说单词cat/cats/kitten,或者run/ran/running都对应不同的分类。注意，增加进一步的监督等等，在词元的前提下，无法产生显著的效果。如果一个词至少一次被用在ground truth标注中，他就数与一个图像的正类。<br>不同词性的平均查准率和人为召回的精确度结果如表3。我们发现人们经常在使用哪些单词而存在分歧，而人类因为不同的单词（通过将一个标题中的单词与其他标题对比来衡量）而存在不同的意见（见附录）。当我们考虑更多的标题时，人类的准确率会提高，但是人类的召回率保持相对不变。因此我们测量了提出的算法在人类召回率方面的精度，并且比较了人类的准确率，衡量得到人类和机器的分类能力的相似性。<br>我们报告了两个蓟县。第一个（chance)是对每个单词随机分类的结果。第二个（Classification）是用我们的MIL方法对相同的特征（CNN的fc6层）做一个简单的窗口训练所有的图像分类器得到的结果。<br>如图3显示，MIL NOR方法提高了所有词性的两个基线，证明更好地定位可以帮助预测单词。实际上，我们发现名词和形容词的提高最大，他们通常对应于图像区域中的具体对象。分类和MIL NOR的在词性方面低的结果可能因为视觉信息少而且难以检测，比如说形容词（few，有着1.94的AP），代词（比如：himself，有着1.71的 AP），和介词（比如：before，有0.68的AP）相比之下，拥有较高AP值的单词，要么是视觉信息丰富的（red：AP:62.4，her：AP：34.7）要么与特定对象相关联（polar:AP:78.6,stuffed:AP:60.3）。图2和图3展示了单词定位的定性结果。<br>6.3标题产生<br>我们接下来描述我们的标题生成结果，首先要讨论评估指标。<br>Metrics:句子生成过程使用自动指标和人工研究来度量。我们使用三个不同的自动指标：PPLX,BLEU和METEOR。PPLX测量句子模型的不确定性，对应的是给定语言模型的每个单词的编码需要多少比特。因此PPLX越低表示得分越高。BLEU广泛应用于机器翻译中，用于测量假设和参考或参考集之间的共有的N-gram（从1到4）。METEOR测量一元模型的精度和查全率，扩展精确的单词匹配包括基于WordNet同义词和词根的相似词汇。<br>所有这些自动指标都已知的只大概的和人类的判断有关。因此，我们也做了众包实验进一步的探索我们模型的质量。每个任务都给众包工作者提供一张图片和两组标题。一个是自动生成的标题，另一个是人工标题。工作人员被要求选择图片描述更好的标题，或者选择同等质量的“相同”的标题。在每组实验中，250个Turker被要求对比20组标题对，5个Turkers判断每个标题对。我们使用Crowdflower，它会自动过滤垃圾邮件的发送者。标题的顺序为了避免偏见使用了随机化，我们加入了四个答案显而易见的检查案例，遗漏这些内容的注解者被排除在外。最终的裁判结果大都出自5个Turkers的裁判。在平局的情况下，一半的计数被分布在两个最佳答案。<br>生成结果：表4总结了我们在MC COCO数据集上的标题生成结果。为了进行试验对比，我们提供了几个基线。这包含两个测量数据集复杂性的基线：Unconditioned Generation，在不知道视觉单词检测器的情况下通过对N-gram语言模型生成的句子采样；Shuffled Human，随机选择另一个人从另一幅画中生成的标题。对于这些方法，BLEU和METEOR的评分都非常低，证明MC COCO数据集有很大的多样性和复杂度。<br>我们提供了三个我们的变形算法的结果，Baseline, Baseline+Score, 和 Baseline+Score+DMSM。Baseline使用表1中所有离散的特征训练的ME LMBaseline+Score将单词检测器来给特征评分加入到ME LM。这两种方法都使用了同一组句子特征（包括DMSM评分），这组特征在第5节使用MERT重排标题顺序时描述过。Baseline+Score+DMSM使用了和Baseline+Score同样的ME LM，但是加入了DMSM得分作为特征重排序。如图4表示。带不带单词检测器得分特征的MELX的PPLX大致相同。在ME LM中增加单词检测测器分数的BLEU和METEOR都有改善；并且加入了重排序的DMSM得分进一步提高。令人惊讶的是，BLEU的分数实际上高于人工标注的标题。（21.05%和19.32%）<br>为了更好的理解我们标题的感知质量，我们报告了人们判断自动标题与人工标题的“相同质量”“更好”“相同或更好”的百分比，并从二项分布标准错误中推导出误差线。我们发现，Baseline+Score+DMSM方法生成的标题有23.3%的几率被判断为与人工标题具有相同或者更好的质量，这是对基线结果的显著改善。注意，给定的错误线假设样本是独立的：如果我们使用McNemar配对测试，即在同一组图片上比较三个系统的结果，那么我们会发现添加了DMSM的我们的系统可以使大多数人的投票情况明显改善，P的值为0.024。最终结果如图4所示。<br>为了能够直接的与以前的工作做对比，我们还在PASCAL语句数据集上做了测试，这个数据集在Midge和Baby Talk系统上都有使用。我们发现在Midge系统上的BLEU和METEOR指标都有显著的提高。Baby Talk会产生多个句子的长标题，很难用BLEU和METEOR做比较。然而，为了给定一个对这个领域飞速发展的基本的定性认识，图4展示了我们系统，Midge系统和Baby Talk系统的输出。<br>7.总结<br>本文提出了一种新的生成图像文本标题的系统。我们的系统同时训练图像和对应的人工标题。这个系统从图像区域中提取名词、动词和形容词。然后这些检测到的单词可以引导语言模型生成包括这些检测到的单词的阅读性良好的文本。最后，我们使用一个全局相似性模型，根据图像和标题在公共向量中的总体相似性，对候选标题进行重排序。<br>我们的系统在以BLEU为指标的衡量方法上超过了人工标题的表现。我们系统的标题被Turkers评定为质量等同于人工标题或者在23.3%的情况下优于人工标题。<br>8.附录<br>附录包括以下几个方面：8.1节提供了关于人类对单词预测的一致看法的一个讨论。8.2提供了我们对自动探测单词的额外的分析。8.3和8.4节给出了关于DMSM模型和BLEU评测标准的进一步的细节。<br>8.关于单词检测的人类共识<br>当我们审查人类对于标题的认识时，我们发现其实在本质上很多相同的东西都有类似的方式。我们可以通过在k+1个人工标题中使用的标注单词以及在前k个引用标题中使用的单词中给定单词ω计算人类精确度和召回率。注意，我们使用了加权的精确度和召回率，每个负类的图像权值为1，每个正类的图像权值等于标题中所含ω的数量。人工精确度（Hp）和人工召回率（Hr）可以通过从K个受试者中有多少个在整个数据集中使用ω去描述给定图像的受试者的数量来计算。<br>我们对一组名词、动词和形容词和所有1000个被考虑进来的单词绘制了Hp-Hr图,如图5。像“大象”这样的动物名词有着很高的召回率，这也就是说，如果“大象”出现在图片中，受试者很有可能去谈论它（直觉上，给定一幅“大象”的图片很稀有，而且没有可以替代“大象”的单词）另一方面，像“BRIGHT”这种形容词使用不一致，因此它的召回率很低。有趣的是，高召回率的单词也有很高的召回率。事实上，所有人类认同的点好像在二维的精确率召回率空间中呈现一维曲线。<br>这个发现促使我们提出一个当受试者使用一个特殊的单词ω描述一张图片时的简单的模型。假设o表示一个对象或者描述视觉概念的单词ω，n表示图像的总数，k表示参考标题的数量。接下来，让q=P（o=1）图像中对象o存在的概率。为了清楚起见，我们将这些定义总结在图6中。我们做了两个简化。首先，我们忽略了图像级别的显著性，而是关注了单词级别的显著性。具体的，我们只对p=P(ω=1|o=1)建模，给定图片中的o受试者使用ω的概率不受图片本身的限制。第二个，我们假设P(ω=1|o=0)=0，也就是受试者不使用ω，除非o在图片中。正如我们即将展示的，即使我们的模型进行了这些简化，也完全可以解释图5中的经验观测值在一个合理的精确度上。<br>基于这些假设，我们可以对只给定p和k的单词ω建立人工精确度Hp和人工召回率Hr的模型。首先，给每个图片k个标题，我们需要计算标题包含单词的期望值cw(1),被模型预测为正的正样本(tp)，被模型预测为正的负样本(fp)。注意在我们的定义里面，每幅图片可以有k个被预测为正的正样本（如果cw=k，也就是所有的k个标题包含的单词ω）但是在模型1中被模型预测为正的负样本（如果k个标题中都没有包含单词ω）。根据k,p和q的期望值为：<br>（公式）<br>上述的ωi次方=1表示ω出现在第i个标题中，注意，我们也假设受o制约的两个受试者之间是独立的。我们可以定义模型的准确率和召回率：<br>（公式）<br>注意，这些表达式只取决于p而跟q无关，有趣的是，由于带有权值的准确率和召回率的使用，给定图片中的o，受试者使用ω的召回率正好等于p。<br>我们假设k=4,改变p来绘制Hp和Hr的图像，得到如图五蓝线所示的曲线（左下）。这条曲线很好的的揭示了所观察的数据，与经验数据的精确度-召回率基本吻合（即使没有那么完美）。我们还可以把标题数量从4个降低，看看经验和预测的准确率和召回率的变化是如何的。图5（右下角）展现出了我们将每张图片的标题数目从4个降到了1个的变化。我们发现人类的一致点保持在一个相同的召回率的值，但是在准确率上却在降低，这与我们的模型预测的一致。同样的，人工召回率对于无限大的受试者来说将趋向于1，这也是合理的，因为受试者只会在图片出现相关的对象时才会使用单词ω（在无限大的受试者的情况下，也依旧会使用单词ω）。<br>事实上，固定的召回率值可以帮助我们恢复p，p是一个受试者可能在给定对象出现的一幅图的描述中会使用单词ω的概率。像“大象”和“网球”这样的名词拥有很大的p值，这是合理的。另一方面，动词和形容词拥有相似的p值，这可以从以下事实中得到证明：(a)主语不太可能来描述对象的属性(b)主语可能用不同的单词(同义词)来描述相同的属性。<br>这些对于人类一致性的分析也促使人们使用不同的指标来衡量系统的表现。我们建议将召回率的准确率作为衡量这一视觉系统的性能指标。假设某一特定词汇的召回率是固定的，而且精度随着注释数目的变化而变化，我们可以看到系统的召回率的准确率和准确率对比，得到视觉系统的性能报告。<br>8.2词检测分析<br>在图6中，我们展示了使用MIL在词频分类上所带来的改进。我们发现频繁出现的单词，MIL给了一个更大的性能提升。对于不太常见的单词，MIL和分类提供了类似的结果。<br>我们系统所使用的的单词列在表7中。<br>8.3DMSM更多的细节<br>在这项任务中，我们使用我们的深度多模态相似性模型(DMSM)去给图像的候选标题按照相关性排序。在这里，我们描述了这个系统训练和验证过程一些细节。<br>DMSM模型将图片和训练集中相对应的标题的相关分数最大化训练，然后对测试图片和生成的标题用语言模型重排序。查询和文档模型（正文中用Λ表示）中的可训练权重是用小批量梯度下降来学习的。我们初步的实验证明，DMDM目标函数可以使用恒定的学习率可靠地进行优化。我们在最初的初步试验中将N和γ固定在40和10上。<br>我们在训练过程中使用验证集平分来选择最佳模型。我们在每次训练验证集之后都测量HBR的值。HBR的计算方法如下：对于每幅图片，我们先计算的最佳秩，最佳秩是任何验证集中的真实标题按照相关性排序ZZ最佳秩的调和平均数。结果表明，调和平均数相比对少数低秩数明暗的ABR的算术平均数更稳定。<br>为了找到性能更好的模型，我们先从最初的的实验数据的子集中识别超参数的有效值。然后我们用不同的架构训练几个模型，每次训练选择验证得分最高的模型。通过这些实验，我们可以观察到网络架构对查询和文档网络的模型性能的影响。自从在ILSVRC2012训练的卷积网络的六层权重层和七层权重层已被证明在不同设置表现良好，我们训练模型也使用了六层或七层预训练固定权重的网络层。在上述研究的基础上，能生成最好的排序性能的最终的模型被用于语言模型生成标题的重排序上。<br>表8总结了我们验证试验的结果。性能最好的架构包含10层用于查询模块的权重层和5层用于文件模型的权重层。查询模型的前七层网络使用了Caffe参考模型并且在训练期间保持不变，所以另一种描述我们的查询模型的办法就是在ILSVRC2012图像分类数据集上训练的网络获得的FC7特性的基础上增加3个全连接层。<br>值得注意的是，总的来说我们发现当使用FC7特征比使用FC6特征有更好的性能。由于这些特征来自ImageNet模型中最接近softmax分类层的层，因此我们可以说拥有更高的区别性的特征对我们特定的实验环境有益。<br>从结果可以明显看出，网络深度对于查询和文件模型都有明显的优势。这对于查询模型来说并不惊奇，网络的深度已被证明对许多计算机视觉任务至关重要。然而，我们看到在这里发现的最佳文本模型与过去的像web搜索模型形成了明显的对比，查询问题和web文档标题是匹配的而图片和文本段不匹配。与自然图片的描述相比搜索查询和web页面标题通常都很短，并且他们的语义表述通常不纠缠在一起。因此我们发现将文档模型的深度增加到5层或6层有助于提高性能。尽管我们的文档目前没有考虑标题中单词的相对顺序，但是它相当好不需要使用显式的依存关系语法就能捕获它们之间的关系。这与最近的神经网络自然语言处理领域的研究一致。<br>8.4BLEU<br>BLEU最初由Papineni等人为了测量机器翻译输出的质量而提出。BLEU-4平分在机器翻译领域和本文中都是常用的。计算方法为（公式）</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/23/2019-to-do-list/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="JiYali">
      <meta itemprop="description" content="研究生期间遇到的问题的记录">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coding With Yali">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019/02/23/2019-to-do-list/" class="post-title-link" itemprop="url">2019 to do list</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-02-23 15:16:03" itemprop="dateCreated datePublished" datetime="2019-02-23T15:16:03+08:00">2019-02-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-03-01 20:01:19" itemprop="dateModified" datetime="2019-03-01T20:01:19+08:00">2019-03-01</time>
              
            
          </span>

          

          
            
            
              
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
            
                <span class="post-meta-item-text">评论数：</span>
                <a href="/2019/02/23/2019-to-do-list/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2019/02/23/2019-to-do-list/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天的的确确是我一个人在办公室了<br>确实有点莫名其妙的感觉<br>爽到飞起也是突然觉得任重道远</p>
<p>想想来读研也算是第二个年头有余了<br>就像哥哥所说的那句话一样<br>之前的坑也没有填好，又开始了新的课题</p>
<p>忙来忙去又是一年始尹</p>
<p>18年做的最成功的感觉就是确定了方向<br>之前都是人家上课我上课 人家找实习我找实习<br>东一头西一脑袋的<br>真的很庸碌<br>甚至自己也一直处在莫名其妙的高压之下</p>
<p>我要做机器学习。<br>我要做自然语言处理。</p>
<p>这是18年的成功之处吧</p>
<p>那么19年就努力的去填坑吧<br>虽然我不聪明<br>虽然一直自我催眠数学差到极致<br>虽然毕业就在眼前了<br>那有什么呢<br>赌上像今天这样空无一人的周末实验室好了</p>

          
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">JiYali</p>
              <div class="site-description motion-element" itemprop="description">研究生期间遇到的问题的记录</div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              

              
            </nav>
          

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/jiyali" title="GitHub &rarr; https://github.com/jiyali" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://weibo.com/3877347556/profile?rightmod=1&wvr=6&mod=personinfo" title="微博 &rarr; https://weibo.com/3877347556/profile?rightmod=1&wvr=6&mod=personinfo" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>微博</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-fas fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">JiYali</span>

  

  
</div>


  <!--<div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>





  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.1.0</div>
-->




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/utils.js?v=7.1.0"></script>

  <script src="/js/motion.js?v=7.1.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.1.0"></script>



  

  


  <script src="/js/next-boot.js?v=7.1.0"></script>


  

  

  

  
  

<script src="//cdn1.lncld.net/static/js/3.11.1/av-min.js"></script>



<script src="//unpkg.com/valine/dist/Valine.min.js"></script>

<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: true,
    notify: true,
    appId: 'bEEICTEdKgYSitT9FQYHTxh7-gzGzoHsz',
    appKey: 'DM9WVs6DaBxGuBXs2flCCS0v',
    placeholder: 'ヾﾉ≧∀≦)o来啊，快活啊!',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: false,
    lang: '' || 'zh-cn'
  });
</script>





  




  

  

  

  

  

  

  

  

  

  

  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false});</script></body>
</html>
