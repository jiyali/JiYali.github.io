<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1"><title>论文笔记-Show and Tell:A Neural Image Caption Generator</title><link rel="shortcut icon" href="/images/avatar.png"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="//cdn.bootcss.com/highlight.js/9.2.0/styles/github.min.css"><script src="//cdn.bootcss.com/highlight.js/9.2.0/highlight.min.js"></script></head><body><nav class="main-nav"><a href="/">Home</a><a href="/archives">Archives</a></nav><div class="profile"><section id="wrapper"><header id="header"><img class="2x" id="avatar" src="/images/avatar.png"><h1>Coding With Yali</h1><h2></h2></header></section></div><section class="post" id="wrapper"><article><header><h1>论文笔记-Show and Tell:A Neural Image Caption Generator</h1><h2 class="headline">Mar 06, 2019 7:45·3k words
·10 minutes read<span class="tags"></span></h2></header><section id="post-body"><p>摘要<br>图像内容的自动描述是连接计算机视觉和自然语言处理的人工智能中的一个基本问题。本文中，我们提出了一种基于深度递归神经网络架构的生成模型，这个模型结合了机器视觉和机器翻译的最新研究进展，这可以用来生成描述图像的自然句子。在给定图片上对模型进行训练，最大化目标描述句子的似然估计。在几个数据集上的实验表明，模型的准确性和它只从图像描述中学习的语言的流畅性。我们通过定量和定性的方式验证了我们的模型在大部分情况下是精确地。例如，当前在Pascal数据集上最先进的BLUE分数（越高越好）为25，我们的方法的到的分数为59，相比之下，人类的表现为69分。我们还展示了在Flickr30k数据集上的BLEU得分的改进，从55到66，在SBU数据集上，从19到27.<br>1.前言<br>能够使用正确的成型的英语句子自动描述一副图片的主要内容是一个非常有挑战性的课题，但是他可以有巨大的影响，比如说帮助视觉受损的人更好的理解网页图像的内容。这个任务要比充分研究的退昂分类或者识别任务困难的多，而这两项任务一直都是计算机视觉领域的主要焦点。事实上，一个描述不仅需要捕获图像中所包含的对象，还需要表达这些对象之间的关系以及他们的属性和他们所涉及的活动。另外，上述语义知识必须用像英语这样的自然语言来表示，这就意味着除了视觉理解，我们还需要语言模型。<br>以前大多数的尝试都是提议将上述子问题的现有方法拼接在一起，来试下图像和它对应描述的转换。我们希望在这一工作中提出一个单一的模型，以图像I作为输入，从一组给定字典中的单词St中，训练产生最大似然概率p(S|I)生成目标序列的单词S={S1,S2,…}，来充分描述图片。<br>我们工作的主要灵感来自最近机器翻译的进步，机器翻译的任务是把用源语言写的句子S通过最大化p(T|S)翻译成目标语言的译文T。多年来，机器翻译也是通过一系列的独立的任务（直接翻译单词，调整单词，重排序等），但是最近的工作表明翻译可以用一个使用RNN的更简单的方式来完成而且达到了最高的性能。一个“encoder”RNN读取原句，并且将它转换成一个丰富的固定长度的向量表示，这个“encoder”反过来可以作为生成目标句子的“decoder”RNN的初始隐藏状态（初始隐藏状态是个啥？）<br>这里，我们建议遵循这个想法，用CNN来替换编码器RNN。在过去几年里，已经有令人信服的证据表明，CNNs可以通过将输入图片嵌入一个固定长度的向量中，生成一个丰富的表现，这个表现可以用于各种视觉任务中。因此，使用CNNs作为图像的“encoder”是自然而然的，首先，对其预训练用来图像分类的任务，并使用最后一层作为生成句子的RNNdecoder的输入。我们称这个模型为“Neural Image Caption”，或者“NIC”。<br>我们的贡献如下。首先，我们为这个问题提供了一个端到端系统。这是一个使用随机梯度下降的完全可训练的神经网络。其次，我们的模型结合了用于视觉和语言的模型的最先进的子网络。这些可以在更大的语料库上进行预训练，从而利用额外的数据。最后，这个系统与最先进的方法相比产生了明显优越的性能；例如，在Pascal数据集上，NIC得到了59分的BLEU分数，目前最先进的方法为25，而人为表现达到了69。在Flickr30k数据集上，我们从55提高到66，在SBU数据集上，我们从19提高到27。<br>2.相关工作<br>从视觉数据生成自然语言描述一直是机器视觉的研究热点，但是主要针对视频。这导致由可视化的原始识别器和结构化的形式语言构成的复杂系统。比如，And-Or Graphs或者logic系统，它们通过通过基于规则的系统进一步转变为自然语言。这些系统都是大量的手工设计的，相对脆弱，而且只在限定额领域进行了演示，比如交通场景或者运动中。<br>自然文本描述静止图像的问题近年来引起了很大的兴趣。借助最近在对象，对象属性和位置的识别方面的研究进展，允许我们驱动自然语言生成系统，尽管这些系统的表达能力有限。Farhadi等人使用detections（信号检测？）来推断使用模板转换为文本的场景元素的三元组。相似的，Li等人以detections开始，使用检测到的对象以及他们之间的关系拼凑出最终的描述。KulKani等人使用了一个比三元组更复杂的graph of detections（探测图），但是使用了基于模板的文本生成。基于语言句法分析的更强大的语言模型也被使用过。以上方法已经能够大致描述图像，但是当生成文本描述时，它们都是手工设计的而且非常严格。<br>大量的研究解决了给定图片描述的排列问题。这些方法基于图像和文本映射到同一向量空间的思想。对于图像查询，检索嵌入空间的与图像相近的描述。最接近的是，神经网络被用于将图像和文字描述嵌入到一起或者(image crops)和句子但是不试图产生新的描述。一般来说，上述方法不能描述以前从未见过的对象组成，即使个别的对象可能出现过在训练数据集中。另外，它们避免解决评估生成的描述有多好的问题。<br>在这项工作中，我们将用于图像分类的深度卷积网络和用于序列建模的循环卷积网络结合在一起，创建了一个生成图像描述的单一网络。RNN是在这种简单的“端到端”网络中上下文中训练的。这个模型受最近机器翻译中序列生成的成功的启发，不同的是我们提供了一个卷积网络处理的图像而不是以一个句子开始。最近的研究是Kiros等人，他们用了一个神经网络，但是是一个前馈的神经网络，给定一幅图片和之前的单词来预测下一个单词。Mao等人最近的研究中使用了递归神经网络来做相同的预测任务。这与最近的提议非常相似，但是有一些重要的区别：我们使用了一个更有力的RNN模型，并直接向RNN模型提供可视化输入，这使得为RNN记录文本解释过的对象成为可能。由于这些看起来似乎无关紧要的差距，我们的系统在已建立的基准上取得了更好的结果。最后，Kiros等人提出使用一个强大的计算机视觉模型和一个编码文本的LSTM建立一个结合多模态嵌入空间。和我们的方法相反，他们使用的是两个独立路径（一个用于图像，一个用于文字）来定义联合嵌入，并且，即使他们可以生成文本，他们的方法在排名上是(highly tuned)(高度调整？？)<br>3.模型<br>本文中，我们提出一个神经和概率框架来生成图像的描述。最近机器翻译的最新进展表明，给定一个强大的句子模型，就有可能通过直接最大化使用“端到端”方式让给定句子的正确翻译的概率实现先进的结果——同时用于训练和推理。<br>这些模型使用现有的递归神经网络，它将变长的输入编码到一个固定维数的向量中，然后利用这些表示形式解码到期望的输出语句。因此，使用相同的方法是很自然的，给定一张图片（而不是源语言的输入语句），一个相同的原理“翻译”成它的描述语句。<br>因此，我们提出使用如下的公式直接最大化给定图像的正确描述的概率：<br>（公式）<br>这里的θ是我们模型的参数，I是图像，S是正确的描述。由于S代表任何句子，它的长度是无限的。因此，利用链式法则对S0,…,SN的联合概率建模，这里的N是这个特殊例子的长度<br>（公式）<br>为了方便起见，我们放弃了对θ的依赖。在训练时，(S,I)是训练样本对，我们使用随机梯度下降法对整个训练集使用如公式(2)所描述的方法进行优化log概率和(进一步的训练详情将在第4节给出)。<br>p(St|I,S0,…,St-1)与循环神经网络建模，可变数量的单词我们假定为t-1(没看懂这句话的原文hhh…),由定长的隐藏状态或内存Ht表示。在看到一个新的输入xt后，使用非线性函数f来更新这个内存：<br>（公式）<br>为了使上述的RNN更加具体，需要作出两个关键的设计选择：f的确切形式是什么，图像和单词怎么才能作为xt的输入。对于f我们使用上短期记忆网络，他在翻译等顺序任务上显示了先进的性能。这个模型将在下一节进行概述。<br>对于图像的图像的表征，我们使用CNN。它们在图像任务中得到了广泛的应用，目前是用于目标识别和检测的最新技术。我们选择CNN是根据它是ILSVRC2014年分类竞赛的获奖作品。此外，它们还被证明可以通过迁移学习推广到其他的任务上去，比如说场景分类。单词用嵌入模型表示。<br>3.1基于LSTM的句子生成器<br>(3)中f的选择取决于它处理消失和爆炸梯度的能力，这是设计和训练RNNs中最常见的挑战。为了处理这种挑战，引入一种特殊的形式的循环网络LSTM，并成功应用于翻译和序列生成。<br>LSTM模型的核心是一个内存单元c编码，它对每一时间步所观察到的内容编码(见图2)。记忆单元的行为是由“门”控制的，门层被多次应用，因此，如果门是1，则可以从门层中保留一个值，如果门值为0，则删掉这个值。特别的是，使用了三个门来控制是否忘记当前的记忆单元的值（遗忘门f）。如果应该读取输入(输入门i），以及是否输出新的单元值（输出门o）。门和单元更新的输出的定义如下：</p>
</section><nav id="post-nav"><span class="prev"></span><span class="next"><a href="/2019/02/25/论文笔记-From-Captions-to-Visual-Concepts-and-Back/">Older Posts<span class="arrow">→</span></a></span></nav></article></section><footer id="footer"><div id="social"><a class="symbol" href="https://github.com/jiyali"><i class="fa fa-github"></i></a></div><p class="small">© Copyright 2018 &nbsp;<i class="fa fa-heart" aria-hidden="true">&nbsp;JYL</i></p><p class="small">Powered by &nbsp;<a href="https://hexo.io/">Hexo &nbsp;</a></p></footer><script>hljs.initHighlightingOnLoad();</script></body></html>